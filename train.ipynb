{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CTGAN model/ synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.datasets.local import load_csvs\n",
    "from sdv.metadata import SingleTableMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Get current timestamp for unique identifiers\n",
    "current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Load real data\n",
    "input_folder = './input/'\n",
    "input_file_name = input(\"Enter the input file name: \").lower()\n",
    "real_data_path = os.path.join(input_folder, input_file_name + '.csv')\n",
    "real_data = pd.read_csv(real_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Manually create metadata that describes our real dataset\n",
    "metadata_dict = {\n",
    "    \"columns\": {\n",
    "        \"Timestamp\": {\n",
    "            \"sdtype\": \"datetime\",\n",
    "            \"datetime_format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "        },\n",
    "        \"Source.IP\": {\n",
    "            \"sdtype\": \"categorical\"\n",
    "        },\n",
    "        \"Source.Port\": {\n",
    "            \"sdtype\": \"categorical\"\n",
    "        },\n",
    "        \"Destination.IP\": {\n",
    "            \"sdtype\": \"categorical\"\n",
    "        },\n",
    "        \"Destination.Port\": {\n",
    "            \"sdtype\": \"categorical\"\n",
    "        },\n",
    "        \"Protocol\": {\n",
    "            \"sdtype\": \"categorical\"\n",
    "        },\n",
    "        \"Flow.Duration\": {\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"Total.Fwd.Packets\": {\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"Total.Backward.Packets\": {\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"Total.Length.of.Fwd.Packets\": {\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"Total.Length.of.Bwd.Packets\": {\n",
    "            \"sdtype\": \"numerical\"\n",
    "        }\n",
    "    },\n",
    "    \"METADATA_SPEC_VERSION\": \"SINGLE_TABLE_V1\"\n",
    "}\n",
    "metadata = SingleTableMetadata.load_from_dict(metadata_dict)\n",
    "# print(metadata)  # DEBUG, validate metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input arguments\n",
    "load_existing = input(\"Do you want to load an existing GAN model? (yes/no): \").lower()\n",
    "if load_existing == \"yes\":\n",
    "    model_name = input(\"Enter the name of the model to load (without '.pkl' extension): \") + '.pkl'\n",
    "    synthesizer = CTGANSynthesizer.load(filepath=model_name)\n",
    "else:\n",
    "    enforce_rounding = input(\"Enforce rounding for synthetic data? (yes [default] /no): \").lower() == \"yes\"  # default true, control whether the synthetic data should have same number of decimal digits as the real data\n",
    "    enforce_min_max_values = input(\"Enforce min/max values for synthetic data? (yes [default] /no): \").lower() == \"yes\"  # default true, control whether the synthetic data should adhere to same min/max boundaries as the real data\n",
    "    epochs = int(input(\"Enter the number of epochs for training (default=300): \") or 300)\n",
    "    cuda = input(\"Enable CUDA computing? (yes/no): \").lower() == \"yes\"\n",
    "    synthesizer = CTGANSynthesizer(\n",
    "        metadata=metadata,\n",
    "        enforce_rounding=enforce_rounding,\n",
    "        enforce_min_max_values=enforce_min_max_values,\n",
    "        epochs=epochs,\n",
    "        verbose=True,\n",
    "        cuda=cuda\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model path: model\\ctgan_filtered_new_data_ep1_mdl1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create model path\n",
    "model_folder = 'model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_base_name = f\"ctgan_{input_file_name}_ep{epochs}_mdl\"  # split argument removes file extension\n",
    "model_number = 1\n",
    "model_name = model_base_name + str(model_number) + '.pkl'\n",
    "model_path = os.path.join(model_folder, model_name)\n",
    "\n",
    "while os.path.exists(model_path):\n",
    "    print('Model path already exists:', model_path)\n",
    "    model_number += 1\n",
    "    model_path = os.path.join(model_folder, model_base_name + str(model_number) + '.pkl')\n",
    "\n",
    "print(\"Final model path:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerformanceAlert: Using the CTGANSynthesizer on this data is not recommended. To model this data, CTGAN will generate a large number of columns.\n",
      "\n",
      "Original Column Name        Est # of Columns (CTGAN)\n",
      "Timestamp                   11\n",
      "Source.IP                   97\n",
      "Source.Port                 2373\n",
      "Destination.IP              524\n",
      "Destination.Port            404\n",
      "Protocol                    3\n",
      "Flow.Duration               11\n",
      "Total.Fwd.Packets           11\n",
      "Total.Backward.Packets      11\n",
      "Total.Length.of.Fwd.Packets 11\n",
      "Total.Length.of.Bwd.Packets 11\n",
      "\n",
      "We recommend preprocessing discrete columns that can have many values, using 'update_transformers'. Or you may drop columns that are not necessary to model. (Exit this script using ctrl-C)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (5.11) | Discrim. (-0.39): 100%|██████████| 1/1 [00:23<00:00, 23.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final logs for losses path: logs\\losses_ctgan_filtered_new_data_ep1_mdl1.pkl.csv\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "synthesizer.fit(real_data)\n",
    "\n",
    "# Save trained model\n",
    "synthesizer.save(filepath=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final logs for losses path:  logs\\losses_ctgan_filtered_new_data_ep1_mdl1.pkl.csv\n"
     ]
    }
   ],
   "source": [
    "# Save model losses in log folder as CSV\n",
    "losses = synthesizer.get_loss_values()\n",
    "model_log_file_name = f'losses_{model_name}_{current_timestamp}.csv'\n",
    "model_log_file_path = os.path.join(log_folder, model_log_file_name)\n",
    "losses.to_csv(model_log_file_path, index=False)\n",
    "\n",
    "print(\"Final logs for losses path: \", model_log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Some outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Generator Loss</th>\n",
       "      <th>Discriminator Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.293233</td>\n",
       "      <td>-0.391187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Generator Loss  Discriminator Loss\n",
       "0      0        5.293233           -0.391187"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
